{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from shutil import get_terminal_size\n",
    "import os\n",
    "import kagglehub\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "import ast\n",
    "\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "print(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "goe1 = os.path.join(current_dir, \"goemotion_dataset/goemotions_1.csv\")\n",
    "goe2 = os.path.join(current_dir, \"goemotion_dataset/goemotions_2.csv\")\n",
    "goe3 = os.path.join(current_dir, \"goemotion_dataset/goemotions_3.csv\")\n",
    "\n",
    "\n",
    "goemotion_df1 = pd.read_csv(goe1)\n",
    "goemotion_df2 = pd.read_csv(goe2)\n",
    "goemotion_df3 = pd.read_csv(goe3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'admiration', 'amusement', 'anger', 'annoyance', 'approval',\n",
       "       'caring', 'confusion', 'curiosity', 'desire', 'disappointment',\n",
       "       'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',\n",
       "       'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride',\n",
       "       'realization', 'relief', 'remorse', 'sadness', 'surprise'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([goemotion_df1, goemotion_df2, goemotion_df3], axis=0, ignore_index=True)\n",
    "\n",
    "df = df[df['example_very_unclear'] == False] # uncler = Trueì¸ row ì œê±°\n",
    "\n",
    "df = df.dropna(subset=['text'])\n",
    "\n",
    "df.drop_duplicates(subset=['text'], inplace=True)\n",
    "\n",
    "df = df.drop(['id', 'author', 'subreddit', 'link_id', 'parent_id', 'created_utc', 'rater_id', 'example_very_unclear','neutral'], axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\kakao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kakao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kakao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(str)\n",
    "df['text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df.loc[:, 'admiration':'surprise'].sum(axis=1) == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['text']\n",
    "emotions = df.loc[:, 'admiration':'surprise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(texts, emotions, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000)  # ìµœëŒ€ 5000ê°œì˜ ë‹¨ì–´ë§Œ ê³ ë ¤\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 350\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_seq_length, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_seq_length, padding='post')\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_pad, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_pad, dtype=torch.long)\n",
    "\n",
    "y_train_array = y_train.to_numpy()  # ë˜ëŠ” y_train.values\n",
    "y_test_array = y_test.to_numpy()\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train_array, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_array, dtype=torch.float32)\n",
    "\n",
    "train_dataset = EmotionDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = EmotionDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=0.25, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        # Binary Cross Entropy Loss\n",
    "        bce_loss = F.binary_cross_entropy(outputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)  # pt = probability of true class\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_file, vocab, embedding_dim):\n",
    "\n",
    "    embedding_index = {}\n",
    "\n",
    "    # GloVe íŒŒì¼ ë¡œë“œ\n",
    "    with open(glove_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype=\"float32\")\n",
    "            embedding_index[word] = vector\n",
    "\n",
    "    # ë‹¨ì–´ ì§‘í•© í¬ê¸° ì •ì˜\n",
    "    vocab_size = len(vocab) + 1  # 0ë²ˆ ì¸ë±ìŠ¤ëŠ” íŒ¨ë”©ì— ì‚¬ìš©\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))  # ì´ˆê¸°í™”\n",
    "\n",
    "    # ë‹¨ì–´ -> GloVe ë²¡í„° ë§¤í•‘\n",
    "    for word, i in vocab.items():\n",
    "        if i >= vocab_size:\n",
    "            continue\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector  # ë§¤í•‘ëœ ë²¡í„° ì¶”ê°€\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000  # ìµœëŒ€ ë‹¨ì–´ ìˆ˜\n",
    "embedding_dim = 128\n",
    "hidden_dim = 64\n",
    "output_dim = y_train.shape[1]  # ê°ì • ë ˆì´ë¸” ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe íŒŒì¼ ê²½ë¡œ ë° ì„ë² ë”© ì°¨ì› ì„¤ì •\n",
    "glove_dir = os.path.join(current_dir, \"glove.6B.100d.txt\")\n",
    "glove_file = glove_dir  # GloVe ì„ë² ë”© íŒŒì¼ ê²½ë¡œ\n",
    "embedding_dim = 100  # GloVe ë²¡í„° ì°¨ì›\n",
    "\n",
    "# í† í¬ë‚˜ì´ì €ì—ì„œ ë‹¨ì–´ ì§‘í•©(vocab) ê°€ì ¸ì˜¤ê¸°\n",
    "vocab = tokenizer.word_index  # í† í¬ë‚˜ì´ì €ì˜ ë‹¨ì–´ -> ì¸ë±ìŠ¤ ë§¤í•‘\n",
    "\n",
    "# GloVe ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±\n",
    "embedding_matrix = load_glove_embeddings(glove_file, vocab, embedding_dim)\n",
    "\n",
    "# PyTorch ëª¨ë¸ ì •ì˜\n",
    "class ImprovedDeepLSTMEmotionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers=3, dropout=0.3, embedding_matrix=None):\n",
    "        super(ImprovedDeepLSTMEmotionModel, self).__init__()\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if embedding_matrix is not None:\n",
    "            self.embedding.weight.data.copy_(torch.tensor(embedding_matrix))  # GloVe ì ìš©\n",
    "            self.embedding.weight.requires_grad = True  # GloVe ë¯¸ì„¸ì¡°ì •(fine-tuning) í™œì„±í™”\n",
    "\n",
    "        # Bi-LSTM Layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=True  # ì–‘ë°©í–¥ LSTM\n",
    "        )\n",
    "\n",
    "        # Conv1D Layer for Feature Extraction\n",
    "        self.conv1d = nn.Conv1d(hidden_dim * 2, hidden_dim, kernel_size=3, padding=1)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Dropout and BatchNorm\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "\n",
    "        # Sigmoid for Multi-label Classification\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        # Bi-LSTM\n",
    "        lstm_out, _ = self.lstm(embedded)  # lstm_out shape: (batch, seq_len, hidden_dim * 2)\n",
    "\n",
    "        # Conv1D\n",
    "        conv_out = self.conv1d(lstm_out.permute(0, 2, 1))  # Conv1D requires (batch, channels, seq_len)\n",
    "        conv_out = F.relu(conv_out)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        pooled = torch.mean(conv_out, dim=2)  # shape: (batch, hidden_dim)\n",
    "\n",
    "        # Batch Normalization\n",
    "        normed = self.batch_norm(pooled)\n",
    "\n",
    "        # Fully Connected + Dropout\n",
    "        output = self.fc(self.dropout(normed))\n",
    "        return self.sigmoid(output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model = ImprovedDeepLSTMEmotionModel(\n",
    "    vocab_size=len(vocab) + 1,\n",
    "    embedding_dim=embedding_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_layers=3,\n",
    "    dropout=0.3,\n",
    "    embedding_matrix=embedding_matrix\n",
    ")\n",
    "\n",
    "# model_dir = os.path.join(current_dir, \"improved_model.pth\")\n",
    "# state_dict = torch.load(model_dir, map_location=torch.device('cpu'))  # state_dict ë¡œë“œ\n",
    "# improved_model.load_state_dict(state_dict)  # state_dictë¥¼ ëª¨ë¸ì— ë¡œë“œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   2%|â–         | 16/1049 [00:08<09:19,  1.85it/s, loss=0.0416]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m texts, labels \u001b[38;5;241m=\u001b[39m texts\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mimproved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ëª¨ë¸ ì¶œë ¥\u001b[39;00m\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)  \u001b[38;5;66;03m# ì†ì‹¤ ê³„ì‚°\u001b[39;00m\n\u001b[0;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# ì—­ì „íŒŒ\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[62], line 51\u001b[0m, in \u001b[0;36mImprovedDeepLSTMEmotionModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     48\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Bi-LSTM\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m lstm_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# lstm_out shape: (batch, seq_len, hidden_dim * 2)\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Conv1D\u001b[39;00m\n\u001b[0;32m     54\u001b[0m conv_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1d(lstm_out\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Conv1D requires (batch, channels, seq_len)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\venv\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1123\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1120\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1137\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1145\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = FocalLoss(gamma=2, alpha=0.25)\n",
    "optimizer = torch.optim.Adam(improved_model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    improved_model.train()  # í•™ìŠµ ëª¨ë“œ í™œì„±í™”\n",
    "    total_loss = 0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for texts, labels in progress_bar:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”\n",
    "        outputs = improved_model(texts)  # ëª¨ë¸ ì¶œë ¥\n",
    "        loss = criterion(outputs, labels)  # ì†ì‹¤ ê³„ì‚°\n",
    "        loss.backward()  # ì—­ì „íŒŒ\n",
    "        optimizer.step()  # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Average Loss: {avg_loss:.4f}\")\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "# í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë¸ ì €ì¥\n",
    "# torch.save(improved_model.state_dict(), \"improved_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_model.eval()  # í‰ê°€ ëª¨ë“œ í™œì„±í™”\n",
    "total_loss = 0\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "progress_bar = tqdm(test_loader, desc=\"Evaluating\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for texts, labels in progress_bar:\n",
    "        texts, labels = texts.to(device), labels.to(device)\n",
    "        outputs = improved_model(texts)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        probabilities = outputs  # Sigmoidê°€ ì´ë¯¸ ì ìš©ëœ ìƒíƒœ\n",
    "        preds = (probabilities > 0.5).float()  # 0.5 ì„ê³„ê°’ìœ¼ë¡œ ì´ì§„í™”\n",
    "\n",
    "        all_labels.append(labels.cpu())\n",
    "        all_preds.append(preds.cpu())\n",
    "\n",
    "        progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "avg_loss = total_loss / len(test_loader)\n",
    "print(f\"Test Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Confusion Matrix ì¶œë ¥\n",
    "all_labels = torch.cat(all_labels).numpy()\n",
    "all_preds = torch.cat(all_preds).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_emotion_confusion_matrix(true_labels, predicted_labels, label_names):\n",
    "\n",
    "    num_labels = len(label_names)\n",
    "    matrix = np.zeros((num_labels, num_labels), dtype=int)\n",
    "\n",
    "    for true, pred in zip(true_labels, predicted_labels):\n",
    "        true_indices = np.where(true == 1)[0]  # True labels\n",
    "        pred_indices = np.where(pred == 1)[0]  # Predicted labels\n",
    "\n",
    "        for t in true_indices:\n",
    "            for p in pred_indices:\n",
    "                matrix[t, p] += 1\n",
    "\n",
    "    return pd.DataFrame(matrix, index=label_names, columns=label_names)\n",
    "\n",
    "# ë ˆì´ë¸” ì´ë¦„\n",
    "emotion_labels = ['admiration', 'amusement', 'anger', 'annoyance', 'approval',\n",
    "       'caring', 'confusion', 'curiosity', 'desire', 'disappointment',\n",
    "       'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',\n",
    "       'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride',\n",
    "       'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']  # ì˜ˆì‹œ\n",
    "\n",
    "conf_matrix_df = calculate_emotion_confusion_matrix(all_labels, all_preds, emotion_labels)\n",
    "\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Confusion Matrix ì‹œê°í™”\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_df, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=emotion_labels, yticklabels=emotion_labels)\n",
    "plt.title(\"Emotion Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Emotion\")\n",
    "plt.ylabel(\"True Emotion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Project\n",
      "    ğŸ“„ .env\n",
      "    ğŸ“„ .gitattributes\n",
      "    ğŸ“„ app.py\n",
      "    ğŸ“„ classification_report_k_10.csv\n",
      "    ğŸ“„ classification_report_k_30.csv\n",
      "    ğŸ“„ df_lstm_training.ipynb\n",
      "    ğŸ“„ glove.6B.100d.txt\n",
      "    ğŸ“„ improved_model.pth\n",
      "    ğŸ“„ improve_lstm.ipynb\n",
      "    ğŸ“„ ml_k_30_train_text_after_process.csv\n",
      "    ğŸ“„ ml_train_text_after_process.csv\n",
      "    ğŸ“„ project_base.ipynb\n",
      "    ğŸ“„ project_base.py\n",
      "    ğŸ“„ random_forest_model_textK_10.pkl\n",
      "    ğŸ“„ random_forest_model_textK_30.pkl\n",
      "    ğŸ“„ README.md\n",
      "    ğŸ“„ total_song_lyrics.csv\n",
      "    ğŸ“„ total_song_lyrics_result.csv\n",
      "    ğŸ“„ total_song_lyrics_result_add_MLk10.csv\n",
      "    ğŸ“„ training_ml_model.ipynb\n",
      "    ğŸ“ Client\n",
      "        ğŸ“„ main.html\n",
      "        ğŸ“„ personer_lyric.html\n",
      "    ğŸ“ emotion_lyric\n",
      "        ğŸ“„ Taylor_Swift\n",
      "        ğŸ“„ Taylor_Swift.csv\n",
      "    ğŸ“ glove\n",
      "        ğŸ“„ glove.6B.100d.txt\n",
      "        ğŸ“„ glove.6B.200d.txt\n",
      "        ğŸ“„ glove.6B.300d.txt\n",
      "        ğŸ“„ glove.6B.50d.txt\n",
      "    ğŸ“ goemotion_dataset\n",
      "        ğŸ“„ goemotions_1.csv\n",
      "        ğŸ“„ goemotions_2.csv\n",
      "        ğŸ“„ goemotions_3.csv\n",
      "    ğŸ“ Lib\n",
      "    ğŸ“ share\n",
      "        ğŸ“ jupyter\n",
      "            ğŸ“ kernels\n",
      "                ğŸ“ python3\n",
      "                    ğŸ“„ kernel.json\n",
      "                    ğŸ“„ logo-32x32.png\n",
      "                    ğŸ“„ logo-64x64.png\n",
      "                    ğŸ“„ logo-svg.svg\n",
      "        ğŸ“ man\n",
      "            ğŸ“ man1\n",
      "                ğŸ“„ ipython.1\n",
      "                ğŸ“„ ttx.1\n",
      "    ğŸ“ song-lyrics-dataset\n",
      "        ğŸ“ csv\n",
      "            ğŸ“„ ArianaGrande.csv\n",
      "            ğŸ“„ Beyonce.csv\n",
      "            ğŸ“„ BillieEilish.csv\n",
      "            ğŸ“„ BTS.csv\n",
      "            ğŸ“„ CardiB.csv\n",
      "            ğŸ“„ CharliePuth.csv\n",
      "            ğŸ“„ ColdPlay.csv\n",
      "            ğŸ“„ Drake.csv\n",
      "            ğŸ“„ DuaLipa.csv\n",
      "            ğŸ“„ EdSheeran.csv\n",
      "            ğŸ“„ Eminem.csv\n",
      "            ğŸ“„ JustinBieber.csv\n",
      "            ğŸ“„ KatyPerry.csv\n",
      "            ğŸ“„ Khalid.csv\n",
      "            ğŸ“„ LadyGaga.csv\n",
      "            ğŸ“„ Maroon5.csv\n",
      "            ğŸ“„ NickiMinaj.csv\n",
      "            ğŸ“„ PostMalone.csv\n",
      "            ğŸ“„ Rihanna.csv\n",
      "            ğŸ“„ SelenaGomez.csv\n",
      "            ğŸ“„ TaylorSwift.csv\n",
      "        ğŸ“ json files\n",
      "            ğŸ“„ Lyrics_ArianaGrande.json\n",
      "            ğŸ“„ Lyrics_Beyonc.json\n",
      "            ğŸ“„ Lyrics_BillieEilish.json\n",
      "            ğŸ“„ Lyrics_BTS.json\n",
      "            ğŸ“„ Lyrics_CardiB.json\n",
      "            ğŸ“„ Lyrics_CharliePuth.json\n",
      "            ğŸ“„ Lyrics_Coldplay.json\n",
      "            ğŸ“„ Lyrics_Drake.json\n",
      "            ğŸ“„ Lyrics_DuaLipa.json\n",
      "            ğŸ“„ Lyrics_EdSheeran.json\n",
      "            ğŸ“„ Lyrics_Eminem.json\n",
      "            ğŸ“„ Lyrics_JustinBieber.json\n",
      "            ğŸ“„ Lyrics_KatyPerry.json\n",
      "            ğŸ“„ Lyrics_Khalid.json\n",
      "            ğŸ“„ Lyrics_LadyGaga.json\n",
      "            ğŸ“„ Lyrics_Maroon5.json\n",
      "            ğŸ“„ Lyrics_NickiMinaj.json\n",
      "            ğŸ“„ Lyrics_PostMalone.json\n",
      "            ğŸ“„ Lyrics_Rihanna.json\n",
      "            ğŸ“„ Lyrics_SelenaGomez.json\n",
      "            ğŸ“„ Lyrics_TaylorSwift.json\n"
     ]
    }
   ],
   "source": [
    "def print_directory_tree(startpath, prefix=\"\"):\n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        level = root.replace(startpath, \"\").count(os.sep)\n",
    "        indent = \" \" * 4 * level\n",
    "        print(f\"{prefix}{indent}ğŸ“ {os.path.basename(root)}\")  # ë””ë ‰í† ë¦¬ ì¶œë ¥\n",
    "        sub_indent = \" \" * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f\"{prefix}{sub_indent}ğŸ“„ {f}\")  # íŒŒì¼ ì¶œë ¥\n",
    "\n",
    "# ì‹¤í–‰\n",
    "print_directory_tree(current_dir)  # your_directory_path_hereì— ì‘ì—… ë””ë ‰í† ë¦¬ ê²½ë¡œ ì…ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
