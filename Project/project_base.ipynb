{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from openai) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from openai) (3.11.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from requests>=2.20->openai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from requests>=2.20->openai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from requests>=2.20->openai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from requests>=2.20->openai) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from aiohttp->openai) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from aiohttp->openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from aiohttp->openai) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from aiohttp->openai) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from aiohttp->openai) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from aiohttp->openai) (1.18.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kakao\\desktop\\ajou_socialnetworkanalysis\\project\\lib\\site-packages (from tqdm->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "# set PYTHONUTF8=1\n",
    "# pip install nrcles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import kagglehub\n",
    "import tqdm\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from nrclex import NRCLex\n",
    "\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kakao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kakao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kakao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords') \n",
    "nltk.download('averaged_perceptron_tagger')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\kakao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kakao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kakao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\kakao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\kakao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\kakao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/deepshah16/song-lyrics-dataset?dataset_version_number=5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19.9M/19.9M [00:05<00:00, 3.47MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\kakao\\.cache\\kagglehub\\datasets\\deepshah16\\song-lyrics-dataset\\versions\\5\n"
     ]
    }
   ],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"deepshah16/song-lyrics-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Path: c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\n",
      "Dataset directory has been copied to: c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\n"
     ]
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "print(\"Current Path:\", current_directory)\n",
    "\n",
    "destination_path = os.path.join(current_directory, \"song-lyrics-dataset\")\n",
    "shutil.copytree(path, destination_path, dirs_exist_ok=True)\n",
    "\n",
    "print(\"Dataset directory has been copied to:\", destination_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lyrics datasets have been saved in `song-lyrics-dataset/csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lyrics Dataset Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\ArianaGrande.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\Beyonce.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\BillieEilish.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\BTS.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\CardiB.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\CharliePuth.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\ColdPlay.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\Drake.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\DuaLipa.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\EdSheeran.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\Eminem.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\JustinBieber.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\KatyPerry.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\Khalid.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\LadyGaga.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\Maroon5.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\NickiMinaj.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\PostMalone.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\Rihanna.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\SelenaGomez.csv\n",
      "c:\\Users\\kakao\\Desktop\\Ajou_SocialNetworkAnalysis\\Project\\song-lyrics-dataset\\csv\\TaylorSwift.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>​cardigan</td>\n",
       "      <td>folklore</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>vintage tee brand new phone high heels on cobb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>​exile</td>\n",
       "      <td>folklore</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>justin vernon i can see you standing honey wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Lover</td>\n",
       "      <td>Lover</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>we could leave the christmas lights up 'til ja...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>​the 1</td>\n",
       "      <td>folklore</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>i'm doing good i'm on some new shit been sayin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Look What You Made Me Do</td>\n",
       "      <td>reputation</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>i don't like your little games don't like your...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Artist                     Title       Album    Year  \\\n",
       "0           0  Taylor Swift                 ​cardigan    folklore  2020.0   \n",
       "1           1  Taylor Swift                    ​exile    folklore  2020.0   \n",
       "2           2  Taylor Swift                     Lover       Lover  2019.0   \n",
       "3           3  Taylor Swift                    ​the 1    folklore  2020.0   \n",
       "4           4  Taylor Swift  Look What You Made Me Do  reputation  2017.0   \n",
       "\n",
       "         Date                                              Lyric  \n",
       "0  2020-07-24  vintage tee brand new phone high heels on cobb...  \n",
       "1  2020-07-24  justin vernon i can see you standing honey wit...  \n",
       "2  2019-08-16  we could leave the christmas lights up 'til ja...  \n",
       "3  2020-07-24  i'm doing good i'm on some new shit been sayin...  \n",
       "4  2017-08-25  i don't like your little games don't like your...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "\n",
    "csv_path = os.path.join(current_directory, \"song-lyrics-dataset\", \"csv\")\n",
    "\n",
    "artists = os.listdir(csv_path)\n",
    "for artist in artists:\n",
    "    lyrics_data = os.path.join(csv_path,artist)\n",
    "    print(lyrics_data)\n",
    "    df1 = pd.read_csv(lyrics_data)\n",
    "\n",
    "# 다 합치는 코드 작성해야함\n",
    "    \n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lyrics Analysis\n",
    "##### 1. Knowledge-based Method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER 감성 분석기 초기화\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    compound = scores['compound']  # 전체적인 감정 점수 (-1~1)\n",
    "    # 긍정, 부정, 중립으로 분류\n",
    "    if compound >= 0.05:\n",
    "        return \"Positive\"\n",
    "    elif compound <= -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_emotions(text):\n",
    "    emotions = NRCLex(text).raw_emotion_scores\n",
    "    # 감정이 없는 경우 0으로 채움\n",
    "    for emotion in ['joy', 'sadness', 'anger', 'fear', 'anticipation', 'trust', 'surprise', 'disgust']:\n",
    "        if emotion not in emotions:\n",
    "            emotions[emotion] = 0\n",
    "    return emotions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dominant_emotion(emotion_scores):\n",
    "    return max(emotion_scores, key=emotion_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Lyric'] = df1['Lyric'].apply(str)\n",
    "df1['Sentiment'] = df1['Lyric'].apply(analyze_sentiment)\n",
    "df1['Compound Score'] = df1['Lyric'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Emotion Scores'] = df1['Lyric'].apply(analyze_emotions)\n",
    "df1['Dominant Emotion'] = df1['Emotion Scores'].apply(dominant_emotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        Artist                     Title       Album    Year  \\\n",
      "0           0  Taylor Swift                 ​cardigan    folklore  2020.0   \n",
      "1           1  Taylor Swift                    ​exile    folklore  2020.0   \n",
      "2           2  Taylor Swift                     Lover       Lover  2019.0   \n",
      "3           3  Taylor Swift                    ​the 1    folklore  2020.0   \n",
      "4           4  Taylor Swift  Look What You Made Me Do  reputation  2017.0   \n",
      "\n",
      "         Date                                              Lyric  \n",
      "0  2020-07-24  vintage tee brand new phone high heels on cobb...  \n",
      "1  2020-07-24  justin vernon i can see you standing honey wit...  \n",
      "2  2019-08-16  we could leave the christmas lights up 'til ja...  \n",
      "3  2020-07-24  i'm doing good i'm on some new shit been sayin...  \n",
      "4  2017-08-25  i don't like your little games don't like your...  \n"
     ]
    }
   ],
   "source": [
    "print(df1.head())\n",
    "df1.to_csv(\"./emotion_lyric/Taylor_Swift.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key: s\n",
      "Organization ID: org-OM19rEiNgQYfx67ywUkPJgSY\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"API Key:\", os.environ.get(\"OPENAI_API_KEY\")[0])\n",
    "print(\"Organization ID:\", os.environ.get(\"OPENAI_ORGANIZATION\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sadness\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Anger\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Joy\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Anger\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Anger\n",
      "Anger\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Anger\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Anger\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Indifference\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Anger\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Nostalgia\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Sadness\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Anger\n",
      "Sadness\n",
      "Joy\n",
      "Sadness\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Fear\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Joy\n",
      "Sadness\n",
      "Sadness\n",
      "Anger\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Sadness.\n",
      "Love\n",
      "Nostalgia.\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Joy\n",
      "Sadness\n",
      "Sadness\n",
      "Anger\n",
      "Anger\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Nostalgia\n",
      "Love\n",
      "Sadness.\n",
      "Joy\n",
      "Anger\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Joy\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Anger\n",
      "Anger\n",
      "Joy\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Anger\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Love\n",
      "Fear\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Anger\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Sadness\n",
      "Surprise\n",
      "Love\n",
      "Joy\n",
      "Sadness\n",
      "Sadness\n",
      "Love\n",
      "Fear\n",
      "Joy\n",
      "Love\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness.\n",
      "Sadness\n",
      "Anger\n",
      "Joy\n",
      "Joy\n",
      "Love\n",
      "Fear\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Sadness\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Sadness\n",
      "Love\n",
      "Sadness.\n",
      "Love\n",
      "Sadness\n",
      "Surprise\n",
      "Joy\n",
      "Love\n",
      "Sadness\n",
      "Anger\n",
      "Love\n",
      "Sadness\n",
      "Joy.\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Joy\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Sadness\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Love\n",
      "Anger\n",
      "Joy\n",
      "Reflection\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Joy\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Joy\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Anger\n",
      "Love\n",
      "Love\n",
      "Love.\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Sadness.\n",
      "Sadness.\n",
      "Sadness.\n",
      "Love\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Anger\n",
      "Love\n",
      "Anger\n",
      "Joy\n",
      "Sadness\n",
      "Surprise\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Anger.\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Joy\n",
      "Love\n",
      "Anger\n",
      "Sadness\n",
      "Nostalgia\n",
      "Joy\n",
      "Joy\n",
      "Sadness\n",
      "Sadness\n",
      "Love\n",
      "Surprise\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Sadness.\n",
      "Love\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Anger\n",
      "Love\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Joy\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Sadness.\n",
      "Love\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Joy\n",
      "Joy\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Sadness\n",
      "Anger\n",
      "Love\n",
      "Love\n",
      "Surprise\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Surprise.\n",
      "Love\n",
      "Anger\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Sadness\n",
      "Joy\n",
      "Surprise\n",
      "Love\n",
      "Love\n",
      "Anger\n",
      "Joy\n",
      "Joy\n",
      "Love\n",
      "Love\n",
      "Anger\n",
      "Love\n",
      "Joy\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Surprise\n",
      "Love\n",
      "Joy\n",
      "Surprise\n",
      "Anger\n",
      "Sadness\n",
      "Surprise\n",
      "Surprise\n",
      "Joy\n",
      "Anger\n",
      "Anger\n",
      "Love\n",
      "Sadness\n",
      "Joy\n",
      "Surprise\n",
      "Surprise\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Sadness\n",
      "Joy\n",
      "Sadness\n",
      "Sadness\n",
      "Joy\n",
      "Surprise\n",
      "Joy\n",
      "Love\n",
      "Sadness\n",
      "Sadness\n",
      "Surprise\n",
      "Surprise\n",
      "Surprise.\n",
      "Love\n",
      "Surprise.\n",
      "Sadness\n",
      "Surprise\n",
      "Sadness\n",
      "Surprise\n",
      "Joy\n",
      "Sadness\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Love.\n",
      "Sadness.\n",
      "Anger\n",
      "Surprise\n",
      "Surprise\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Love\n",
      "Joy\n",
      "Surprise\n",
      "Love\n",
      "Sadness\n",
      "Surprise\n",
      "Sadness\n",
      "Surprise.\n",
      "Anger\n",
      "Love\n",
      "Surprise\n",
      "Sadness\n",
      "Love\n",
      "Anger\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Surprise\n",
      "Anger\n",
      "Anger\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Surprise\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Joy\n",
      "Sadness.\n",
      "Anger\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Sadness\n",
      "Anger\n",
      "Love\n",
      "Sadness\n",
      "Love\n",
      "Love\n",
      "Love\n",
      "Joy\n",
      "Anger\n",
      "Sadness\n",
      "Anger\n",
      "Joy\n",
      "Anger\n",
      "Sadness\n",
      "Joy\n",
      "Joy\n",
      "Sadness\n",
      "Love\n",
      "['Sadness', 'Sadness', 'Love', 'Sadness', 'Anger', 'Love', 'Love', 'Joy', 'Joy', 'Sadness', 'Love', 'Love', 'Sadness', 'Love', 'Sadness', 'Love', 'Joy', 'Love', 'Love', 'Love', 'Anger', 'Love', 'Love', 'Sadness', 'Sadness', 'Love', 'Sadness', 'Love', 'Anger', 'Anger', 'Love', 'Love', 'Joy', 'Love', 'Sadness', 'Love', 'Sadness', 'Anger', 'Sadness', 'Sadness', 'Sadness', 'Sadness', 'Sadness', 'Anger', 'Love', 'Love', 'Love', 'Sadness', 'Love', 'Love', 'Love', 'Love', 'Love', 'Sadness', 'Indifference', 'Sadness', 'Love', 'Love', 'Love', 'Anger', 'Love', 'Love', 'Love', 'Sadness', 'Love', 'Nostalgia', 'Sadness', 'Love', 'Love', 'Sadness', 'Sadness', 'Joy', 'Love', 'Love', 'Love', 'Sadness', 'Sadness', 'Sadness', 'Anger', 'Sadness', 'Joy', 'Sadness', 'Joy', 'Love', 'Love', 'Love', 'Love', 'Love', 'Sadness', 'Love', 'Fear', 'Love', 'Sadness', 'Love', 'Joy', 'Sadness', 'Sadness', 'Anger', 'Love', 'Love', 'Joy', 'Sadness.', 'Love', 'Nostalgia.', 'Love', 'Love', 'Sadness', 'Joy', 'Sadness', 'Sadness', 'Anger', 'Anger', 'Sadness', 'Love', 'Sadness', 'Sadness', 'Sadness', 'Sadness', 'Nostalgia', 'Love', 'Sadness.', 'Joy', 'Anger', 'Sadness', 'Love', 'Sadness', 'Joy', 'Sadness', 'Sadness', 'Sadness', 'Sadness', 'Love', 'Sadness', 'Love', 'Love', 'Sadness', 'Love', 'Love', 'Love', 'Anger', 'None', 'Anger', 'Joy', 'Sadness', 'Love', 'Love', 'Sadness', 'Anger', 'Sadness', 'Love', 'Sadness', 'Sadness', 'Sadness', 'Love', 'Fear', 'Joy', 'Love', 'Love', 'Love', 'Anger', 'Love', 'Love', 'Love', 'Love', 'Love', 'Sadness', 'Sadness', 'Surprise', 'Love', 'Joy', 'Sadness', 'Sadness', 'Love', 'Fear', 'Joy', 'Love', 'Sadness', 'Sadness', 'Sadness.', 'Sadness', 'Anger', 'Joy', 'Joy', 'Love', 'Fear', 'Love', 'Love', 'Joy', 'Sadness', 'Joy', 'Love', 'Love', 'Sadness', 'Sadness', 'Love', 'Sadness.', 'Love', 'Sadness', 'Surprise', 'Joy', 'Love', 'Sadness', 'Anger', 'Love', 'Sadness', 'Joy.', 'Love', 'Love', 'Love', 'Joy', 'Joy', 'Sadness', 'Love', 'Love', 'Joy', 'Sadness', 'Joy', 'Love', 'Love', 'Love', 'Love', 'Joy', 'Love', 'Anger', 'Joy', 'Reflection', 'Love', 'Love', 'Sadness', 'Joy', 'Sadness', 'Love', 'Love', 'Love', 'Love', 'Sadness', 'Love', 'Sadness', 'Joy', 'Joy', 'Love', 'Love', 'Love', 'Joy', 'Anger', 'Love', 'Love', 'Love.', 'Love', 'Love', 'Love', 'Sadness.', 'Sadness.', 'Sadness.', 'Love', 'Joy', 'Love', 'Love', 'Joy', 'Love', 'Love', 'Love', 'Anger', 'Love', 'Anger', 'Joy', 'Sadness', 'Surprise', 'Sadness', 'Love', 'Love', 'Love', 'Sadness', 'Sadness', 'Love', 'Love', 'Love', 'Love', 'Love', 'Anger.', 'Love', 'Sadness', 'Love', 'Love', 'Sadness', 'Joy', 'Love', 'Anger', 'Sadness', 'Nostalgia', 'Joy', 'Joy', 'Sadness', 'Sadness', 'Love', 'Surprise', 'Sadness', 'Love', 'Love', 'Sadness.', 'Love', 'Sadness', 'Sadness', 'Sadness', 'Anger', 'Love', 'Joy', 'Love', 'Love', 'Sadness', 'Joy', 'Love', 'Sadness', 'Love', 'Joy', 'Love', 'Love', 'Sadness', 'Sadness.', 'Love', 'Sadness', 'Sadness', 'Sadness', 'Love', 'Sadness', 'Love', 'Sadness', 'Joy', 'Joy', 'Joy', 'Love', 'Love', 'Love', 'Joy', 'Sadness', 'Anger', 'Love', 'Love', 'Surprise', 'Sadness', 'Love', 'Love', 'Surprise.', 'Love', 'Anger', 'Sadness', 'Sadness', 'Sadness', 'Sadness', 'Joy', 'Surprise', 'Love', 'Love', 'Anger', 'Joy', 'Joy', 'Love', 'Love', 'Anger', 'Love', 'Joy', 'Sadness', 'Love', 'Love', 'Joy', 'Surprise', 'Love', 'Joy', 'Surprise', 'Anger', 'Sadness', 'Surprise', 'Surprise', 'Joy', 'Anger', 'Anger', 'Love', 'Sadness', 'Joy', 'Surprise', 'Surprise', 'Sadness', 'Love', 'Love', 'Joy', 'Sadness', 'Joy', 'Sadness', 'Sadness', 'Joy', 'Surprise', 'Joy', 'Love', 'Sadness', 'Sadness', 'None', 'Surprise', 'Surprise', 'Surprise.', 'Love', 'Surprise.', 'Sadness', 'Surprise', 'Sadness', 'Surprise', 'Joy', 'Sadness', 'Sadness', 'Love', 'Love', 'Love', 'Love', 'Love', 'Love.', 'Sadness.', 'Anger', 'Surprise', 'Surprise', 'Sadness', 'Love', 'Love', 'Joy', 'Love', 'Joy', 'Surprise', 'Love', 'Sadness', 'Surprise', 'Sadness', 'Surprise.', 'Anger', 'Love', 'Surprise', 'Sadness', 'Love', 'Anger', 'Sadness', 'Love', 'Love', 'Surprise', 'Anger', 'Anger', 'Love', 'Love', 'Love', 'Sadness', 'Love', 'Surprise', 'Love', 'Love', 'Joy', 'Joy', 'Sadness.', 'Anger', 'Love', 'Love', 'Love', 'Sadness', 'Love', 'Sadness', 'Love', 'Sadness', 'Anger', 'Love', 'Sadness', 'Love', 'Love', 'Love', 'Joy', 'Anger', 'Sadness', 'Anger', 'Joy', 'Anger', 'Sadness', 'Joy', 'Joy', 'Sadness', 'Love']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>GPT_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>​cardigan</td>\n",
       "      <td>folklore</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>vintage tee brand new phone high heels on cobb...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>​exile</td>\n",
       "      <td>folklore</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>justin vernon i can see you standing honey wit...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Lover</td>\n",
       "      <td>Lover</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>we could leave the christmas lights up 'til ja...</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>​the 1</td>\n",
       "      <td>folklore</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>i'm doing good i'm on some new shit been sayin...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Look What You Made Me Do</td>\n",
       "      <td>reputation</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>i don't like your little games don't like your...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Artist                     Title       Album    Year  \\\n",
       "0           0  Taylor Swift                 ​cardigan    folklore  2020.0   \n",
       "1           1  Taylor Swift                    ​exile    folklore  2020.0   \n",
       "2           2  Taylor Swift                     Lover       Lover  2019.0   \n",
       "3           3  Taylor Swift                    ​the 1    folklore  2020.0   \n",
       "4           4  Taylor Swift  Look What You Made Me Do  reputation  2017.0   \n",
       "\n",
       "         Date                                              Lyric GPT_emotion  \n",
       "0  2020-07-24  vintage tee brand new phone high heels on cobb...     Sadness  \n",
       "1  2020-07-24  justin vernon i can see you standing honey wit...     Sadness  \n",
       "2  2019-08-16  we could leave the christmas lights up 'til ja...        Love  \n",
       "3  2020-07-24  i'm doing good i'm on some new shit been sayin...     Sadness  \n",
       "4  2017-08-25  i don't like your little games don't like your...       Anger  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "openai_org = os.environ.get(\"OPENAI_ORGANIZATION\")\n",
    "\n",
    "client = OpenAI(api_key = openai_api_key ,organization =openai_org)\n",
    "\n",
    "def add_sentiment_gpt_api(lyric):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant and has responsible for my Music Lyric Analyze Project.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": '\"'+ lyric + '\"' + \" is one of Taylor Swift's songs lyric. Can you read this and tell me which of the following emotions the lyrics belong to? Just pick one emotion and say it without explanation. Don't pick another emotion, choose only one from the next, and if it's not among the next, call it 'Others'. List: [sadness,surprise,joy,anger,love,surprise,fear]\"\n",
    "                 # 는 Taylor Swift의 노래 중 하나의 가사 전부야. 이걸 읽고, 가사가 다음 감정 중 어느 감정에 속하는지 알려줄래? 다른 설명 없이 감정 하나만 골라서 말해. ['sadness','surprise','joy','anger','love','surprise','fear'].\"\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "results = []\n",
    "for index, row in df1.iterrows():\n",
    "    lyric = row['Lyric']\n",
    "    if type(lyric) == str:\n",
    "        emotion = add_sentiment_gpt_api(lyric)\n",
    "        results.append(emotion)\n",
    "        print(emotion)\n",
    "    else:\n",
    "        results.append(\"None\")\n",
    "\n",
    "print(results)\n",
    "\n",
    "df1['GPT_emotion'] = results\n",
    "df1.head()\n",
    "\n",
    "\n",
    "\n",
    "# print(completion.choices[0].message)\n",
    "# # 프롬프트 생성\n",
    "# prompt = df1.iloc[0]['Lyric'] + \"는 Taylor Swift의 노래 중 하나의 가사 전부야. 이걸 읽고, 가사가 다음 감정 중 어느 감정에 속하는지 알려줄래? [기쁨,슬픔,신남,분노]\"\n",
    "# print(prompt)\n",
    "\n",
    "# # GPT 모델 호출\n",
    "# response = get_completion(prompt)\n",
    "# print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album</th>\n",
       "      <th>Year</th>\n",
       "      <th>Date</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>GPT_emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>​cardigan</td>\n",
       "      <td>folklore</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>vintage tee brand new phone high heels on cobb...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>​exile</td>\n",
       "      <td>folklore</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>justin vernon i can see you standing honey wit...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Lover</td>\n",
       "      <td>Lover</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>we could leave the christmas lights up 'til ja...</td>\n",
       "      <td>Love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>​the 1</td>\n",
       "      <td>folklore</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>i'm doing good i'm on some new shit been sayin...</td>\n",
       "      <td>Sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>Look What You Made Me Do</td>\n",
       "      <td>reputation</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>2017-08-25</td>\n",
       "      <td>i don't like your little games don't like your...</td>\n",
       "      <td>Anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Artist                     Title       Album    Year  \\\n",
       "0           0  Taylor Swift                 ​cardigan    folklore  2020.0   \n",
       "1           1  Taylor Swift                    ​exile    folklore  2020.0   \n",
       "2           2  Taylor Swift                     Lover       Lover  2019.0   \n",
       "3           3  Taylor Swift                    ​the 1    folklore  2020.0   \n",
       "4           4  Taylor Swift  Look What You Made Me Do  reputation  2017.0   \n",
       "\n",
       "         Date                                              Lyric GPT_emotion  \n",
       "0  2020-07-24  vintage tee brand new phone high heels on cobb...     Sadness  \n",
       "1  2020-07-24  justin vernon i can see you standing honey wit...     Sadness  \n",
       "2  2019-08-16  we could leave the christmas lights up 'til ja...        Love  \n",
       "3  2020-07-24  i'm doing good i'm on some new shit been sayin...     Sadness  \n",
       "4  2017-08-25  i don't like your little games don't like your...       Anger  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Statistical Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Deep Learning Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ArianaGrande.csv',\n",
       " 'Beyonce.csv',\n",
       " 'BillieEilish.csv',\n",
       " 'BTS.csv',\n",
       " 'CardiB.csv',\n",
       " 'CharliePuth.csv',\n",
       " 'ColdPlay.csv',\n",
       " 'Drake.csv',\n",
       " 'DuaLipa.csv',\n",
       " 'EdSheeran.csv',\n",
       " 'Eminem.csv',\n",
       " 'JustinBieber.csv',\n",
       " 'KatyPerry.csv',\n",
       " 'Khalid.csv',\n",
       " 'LadyGaga.csv',\n",
       " 'Maroon5.csv',\n",
       " 'NickiMinaj.csv',\n",
       " 'PostMalone.csv',\n",
       " 'Rihanna.csv',\n",
       " 'SelenaGomez.csv',\n",
       " 'TaylorSwift.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
